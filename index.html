<!DOCTYPE html>
<html>
  <head>
    <meta charset='utf-8'>
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    <link href='https://fonts.googleapis.com/css?family=Architects+Daughter' rel='stylesheet' type='text/css'>
    <link rel="stylesheet" type="text/css" href="stylesheets/stylesheet.css" media="screen">
    <link rel="stylesheet" type="text/css" href="stylesheets/github-light.css" media="screen">
    <link rel="stylesheet" type="text/css" href="stylesheets/print.css" media="print">

    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->

    <title>Gram Cracker  by jfelzone</title>
  </head>

  <body>
    <header>
      <div class="inner">
        <h1>Gram Cracker </h1>
        <h2>a project using image recognition with machine learning to predict Instagram Image success</h2>
        <a href="https://github.com/jfelzone/cs5660AI" class="button"><small>View project on</small> GitHub</a>
      </div>
    </header>

    <div id="content-wrapper">
      <div class="inner clearfix">
        <section id="main-content">
          <p>This was my final class project for our Intelligent Systems class.
For this project my goal was to analyze and model the growing explosive social media website Instagram.</p>

<h3>
<a id="the-question" class="anchor" href="#the-question" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>The Question:</h3>

<p>is there an underlying model beneath the pixels of every Instagram account that could be extracted through image recognition and image modeling to successfully predict the number of likes that a user would get on a new image added to their account?</p>

<h3>
<a id="the-objective" class="anchor" href="#the-objective" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>The Objective:</h3>

<p>to create an intelligent system that can look at a new user's picture and predict the number of likes it would receive.</p>

<h3>
<a id="the-approach" class="anchor" href="#the-approach" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>The Approach:</h3>

<p>My initial approach for this project was to use Artificial Neural Networks to analyze images and see if an underlying model existed on the appearance of an image within a user account to successfully determine the success that a given image would have.</p>

<p>Neural Network Structure:
<img src="https://github.com/jfelzone/cs5660AI/blob/master/images/neuralNet.jpeg?raw=true" alt="ANN"></p>

<p>The first thing needed was to gather the data. To gather the data I implemented two main libraries and techniques. I used pyautogui, pytesseract, and PIL to gather my images from Instagram.</p>

<div class="highlight highlight-source-python"><pre><span class="pl-k">import</span> pyautogui
<span class="pl-k">import</span> pytesseract
<span class="pl-k">from</span> <span class="pl-c1">PIL</span> <span class="pl-k">import</span> Image</pre></div>

<h3>
<a id="gathering-the-data" class="anchor" href="#gathering-the-data" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Gathering the Data:</h3>

<p>Before using the three libraries above I actually attempted to use the Instagram API, but quickly read and discovered that the number of API calls I could make an hour simply wasn't going to be enough for the amount of data that I wished to collect. Thus my reasoning for using the above libraries.</p>

<p>Pyautogui is a python library that allows for the manipulation and usage of the gui features of your computer (such as your mouse and keyboard). I used this library (along with PIL imaging library) to manipulate the browser on my computer screen to scroll through instagram accounts, and take screenshots of each picture within the account. This was how I gathered my images.</p>

<p>I then used pytesseract to extract the number of likes from the screenshots that I took. The library is a wrapper to Google's OCR and allows for text extraction from images. With enlarged and zoomed screenshots I gained very high accuracy in being able to extract likes from an image. Essentially I was detecting the below piece highlighted in red:</p>

<h5>
<a id="pytesseract-like-extraction" class="anchor" href="#pytesseract-like-extraction" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>pytesseract like extraction:</h5>

<p><img src="https://github.com/jfelzone/cs5660AI/blob/master/images/likeExtract.png?raw=true" alt="Like Extract"></p>

<p>A video of the file <strong>gatherInsta.py</strong> in action can be seen below: (this shows the gui manip in action, click image to follow link to YouTube)</p>

<p><a href="https://www.youtube.com/watch?v=hiEfYRPM93M&amp;t=62s"><img src="https://github.com/jfelzone/cs5660AI/blob/master/images/imageGather.png?raw=true" alt="Video"></a></p>

<h3>
<a id="pre-processing-observations-account-behavor-analysis" class="anchor" href="#pre-processing-observations-account-behavor-analysis" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Pre-Processing Observations, Account Behavor Analysis:</h3>

<p>Now, with the data in my hand, I was ready to jump into the algorithm and prediciton analysis of the data. However, before doing this, I did an inital analysis on the behavior of various accounts over time. This is shown in the <strong>accountPlotsOverTime.py</strong> file.
within this file I used the following libraries:</p>

<div class="highlight highlight-source-python"><pre><span class="pl-k">import</span> matplotlib.pyplot <span class="pl-k">as</span> plt
<span class="pl-k">import</span> numpy <span class="pl-k">as</span> np
<span class="pl-k">import</span> time</pre></div>

<p>Using matplot lib I was able to generate several scatter plot graphs as well as numpy to calculate the behavor of an account over time. What was observed is that typically speaking an account that has gained traction will have the following scatter plot representation:</p>

<p><img src="https://github.com/jfelzone/cs5660AI/blob/master/images/plotOverTimeNeg.png?raw=true" alt="Neg Res" title="negative regression"></p>

<p>We can observe from this image that typically as an account gains traction the increase in likes over time generally increases. As the x axis increases on the graph we are seeing a further and further look back in time for the given Instagram account.
About 70% of the accounts that I pulled data for had the following format with a negative slope on the regression line.
However there were a few with the following format as well:
<img src="https://github.com/jfelzone/cs5660AI/blob/master/images/plotOverTimePos.png?raw=true" alt="Positive Regression" title="positive regression"></p>

<p>As we can observe, there is very little correlation amongst the images as well as a positive regression line. This would lead us to assume that there will be inherant errer within our results as we do not have images that seem to follow and overly distinct pattern. Thus, initally I hypothesized that our margin of error could be quite large on images that do not follow a consisten like count over time.</p>

<h3>
<a id="the-meat-of-it-algorithm-time" class="anchor" href="#the-meat-of-it-algorithm-time" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>The Meat of It: Algorithm Time:</h3>

<p>The first neural network library that I used was a python Neural Network library called PyBrain. The usage for this library can be seen in the following file <strong>neuralNetwork.py</strong>
To import pybrain the following import statements were use:</p>

<div class="highlight highlight-source-python"><pre><span class="pl-k">import</span> pyautogui
<span class="pl-k">from</span> pybrain.datasets.supervised <span class="pl-k">import</span> SupervisedDataSet 
<span class="pl-k">from</span> pybrain.tools.shortcuts <span class="pl-k">import</span> buildNetwork
<span class="pl-k">from</span> pybrain.supervised.trainers <span class="pl-k">import</span> BackpropTrainer
<span class="pl-k">import</span> cv2
<span class="pl-k">import</span> time
<span class="pl-k">import</span> math</pre></div>

<p>These imports allowed me to build a neural network within pybrain. I used cv2 to read in images and then convert them into one dimensional arrays of RGB pixel values.</p>

<p>We can see the code in the file starting on line 73 which added samples to the neural network based on the loadImage function that generated the list/array of pixel values:</p>

<div class="highlight highlight-source-python"><pre><span class="pl-k">for</span> i <span class="pl-k">in</span> <span class="pl-c1">range</span>(<span class="pl-c1">0</span>,<span class="pl-c1">21</span>):
        <span class="pl-k">try</span>:
            ds.addSample(loadImage(imgdirectory<span class="pl-k">+</span><span class="pl-s"><span class="pl-pds">'</span>img_<span class="pl-pds">'</span></span><span class="pl-k">+</span><span class="pl-c1">str</span>(i)<span class="pl-k">+</span><span class="pl-s"><span class="pl-pds">'</span>.png<span class="pl-pds">'</span></span>), (imgHash[<span class="pl-s"><span class="pl-pds">'</span>img_<span class="pl-pds">'</span></span><span class="pl-k">+</span><span class="pl-c1">str</span>(i)<span class="pl-k">+</span><span class="pl-s"><span class="pl-pds">'</span>.png<span class="pl-pds">'</span></span>],))
        <span class="pl-k">except</span>:
            <span class="pl-c1">print</span> <span class="pl-s"><span class="pl-pds">"</span>Image does not exist, cannot be added to training data<span class="pl-pds">"</span></span>

    trainer <span class="pl-k">=</span> BackpropTrainer(net, ds)
    error <span class="pl-k">=</span> <span class="pl-c1">10</span>
    iteration <span class="pl-k">=</span> <span class="pl-c1">0</span>
    <span class="pl-k">while</span> error <span class="pl-k">&gt;</span> <span class="pl-c1">0.001</span>:
        error <span class="pl-k">=</span> trainer.train()
        iteration <span class="pl-k">+=</span> <span class="pl-c1">1</span>
        <span class="pl-c1">print</span> <span class="pl-s"><span class="pl-pds">"</span>Iteration: <span class="pl-c1">{0}</span> Error <span class="pl-c1">{1}</span><span class="pl-pds">"</span></span>.format(iteration, error)</pre></div>

<p>This library was moderately successful when tested. I had an average margin of error of 30.3% prediction. This metric was derived from scientific error based on the comparison of the actual result and the experimental result and then calculating the error between them. This was a fairly small margin however I was only able to train 20 images in 6.7 hours.
I needed to find something better.</p>

<h3>
<a id="the-sci-kit-learn-stack" class="anchor" href="#the-sci-kit-learn-stack" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>The Sci-Kit Learn Stack:</h3>

<p>At this point in my project I decided I would try to use Sci-Kit learn to test the speed performance in comparison to PyBrain. PyBrain was advertised to be extremely fast and scalable, thus I assumed it would be one of the better libraries, and Sci-Kit learn says on its documentation page that it is not industry speed standard. However, after reading that Sci-Kit learn is built on top of numpy and scipy I figured there was potential for not only a higher performance in speed, but also an increased performance in accuracy. </p>

<p>Thus, I created the following first test file using Sci-Kit Learn: <strong>sciKitNeuralNetwork.py</strong>
I needed to import the following lines of code to run the algorithm:</p>

<div class="highlight highlight-source-python"><pre><span class="pl-k">from</span> sklearn.neural_network <span class="pl-k">import</span> MLPClassifier
<span class="pl-k">import</span> time
<span class="pl-k">import</span> cv2
<span class="pl-k">import</span> random</pre></div>

<p>In order to call the Neural Network classifier (MLP; Multi-Layered Perceptron) I ran the following code on lines 78 and 79:</p>

<div class="highlight highlight-source-python"><pre>clf <span class="pl-k">=</span> MLPClassifier(<span class="pl-v">activation</span><span class="pl-k">=</span><span class="pl-s"><span class="pl-pds">'</span>logistic<span class="pl-pds">'</span></span>, <span class="pl-v">solver</span><span class="pl-k">=</span><span class="pl-s"><span class="pl-pds">'</span>lbfgs<span class="pl-pds">'</span></span>, <span class="pl-v">alpha</span><span class="pl-k">=</span><span class="pl-c1">0.001</span>, <span class="pl-v">hidden_layer_sizes</span><span class="pl-k">=</span>(<span class="pl-c1">35</span>, <span class="pl-c1">20</span>), <span class="pl-v">random_state</span><span class="pl-k">=</span><span class="pl-c1">1</span>, <span class="pl-v">max_iter</span><span class="pl-k">=</span><span class="pl-c1">1000</span>)
    clf.fit(<span class="pl-c1">X</span>, y)</pre></div>

<p>I loaded the images the same way as I did using PyBrain and found a drastic speed boost using Sci-Kit learn. I could load 4 times as many images in a sixth of the time.</p>

<p>With this increased speed boost, and ease of access I then decided to test several different algorithms. 
These are found in the following files: <strong>svmInsta.py</strong> <strong>randomForestInsta.py</strong> where I tested my results using both SVM and Random Forest Algorithms.
The results are shown below:</p>

<p><img src="https://github.com/jfelzone/cs5660AI/blob/master/images/results.png?raw=true" alt="results"></p>

<p>The second metric was more of a curiosity thing on my part. I wanted to know the percentage of the time that the algorithm predicted within the correct number of digits as well. We would expect this to be much higher and it indeed was. </p>

<h3>
<a id="my-final-steps" class="anchor" href="#my-final-steps" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>My final steps</h3>

<p>At this point, I had gotten some very interesting results. I would never have expected a Random Forest algorithm to handle image recognition better than a neural network, however, that was the case. My lowest scientific margin of error was found using a random forest. Where on average my model was predicting off by only 38%.</p>

<p>At this point, I dove down one more rabbit hole. I wanted to be able to load more images in order to increase my training set and thus increase my accuracy. To do this I used the <strong>imageReduction.py</strong> script. </p>

<p>This file had one main difference. It shrunk the features of the images by converting them to a grey scale image. This code is show below:</p>

<div class="highlight highlight-source-python"><pre><span class="pl-k">def</span> <span class="pl-en">smallImageLoad</span>(<span class="pl-smi">path</span>):
    image <span class="pl-k">=</span> Image.open(path).convert(<span class="pl-s"><span class="pl-pds">'</span>L<span class="pl-pds">'</span></span>)
    pix <span class="pl-k">=</span> np.asarray(image)
    oneDpixelArray <span class="pl-k">=</span> []
    <span class="pl-k">for</span> i <span class="pl-k">in</span> pix:
        <span class="pl-k">for</span> j <span class="pl-k">in</span> i:
            oneDpixelArray.append(j)

    <span class="pl-k">return</span> oneDpixelArray</pre></div>

<p>This code thus shrunk my 1D arrays from 270,000 elements to only 90,000 and I was able to load many more images into memory in order to run my final results.</p>

<p>With this improved data set, I found an increase in my predictions.</p>

<div class="highlight highlight-source-python"><pre><span class="pl-c1">print</span> <span class="pl-s"><span class="pl-pds">"</span>Training the classifier<span class="pl-pds">"</span></span>
        <span class="pl-c"># i want to see how slow NN is now</span>
        <span class="pl-c">#clf = MLPClassifier(activation='logistic', solver='lbfgs', alpha=0.001, hidden_layer_sizes=(35, 20), random_state=1, max_iter=1000)</span>
        clf <span class="pl-k">=</span> RandomForestClassifier(<span class="pl-v">n_estimators</span><span class="pl-k">=</span><span class="pl-c1">500</span>)
        clf.fit(<span class="pl-c1">X</span>, y)</pre></div>

<p>After running both the Neural Network and Random Forests I got the following improved results:</p>

<h4>
<a id="neural-network-margin-of-error-20" class="anchor" href="#neural-network-margin-of-error-20" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Neural Network Margin of Error: 20%</h4>

<h4>
<a id="random-forest-margin-of-error-22" class="anchor" href="#random-forest-margin-of-error-22" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Random Forest Margin of Error 22%</h4>

<h3>
<a id="in-conclusion" class="anchor" href="#in-conclusion" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>In Conclusion</h3>

<p>As we can conclude, I got some interesting results from this project as well as developed a baseline framework for continuing to pursue an algorithm that could predict Instagram image success within a margin of error of as low as 5% or 10%. That will be my goal in the continuation of this project after the course of the class. I intend to look into other features that could be added to training set in order to get an even higher prediction accuracy.</p>
        </section>

        <aside id="sidebar">
          <a href="https://github.com/jfelzone/cs5660AI/zipball/master" class="button">
            <small>Download</small>
            .zip file
          </a>
          <a href="https://github.com/jfelzone/cs5660AI/tarball/master" class="button">
            <small>Download</small>
            .tar.gz file
          </a>

          <p class="repo-owner"><a href="https://github.com/jfelzone/cs5660AI"></a> is maintained by <a href="https://github.com/jfelzone">jfelzone</a>.</p>

          <p>This page was generated by <a href="https://pages.github.com">GitHub Pages</a> using the Architect theme by <a href="https://twitter.com/jasonlong">Jason Long</a>.</p>
        </aside>
      </div>
    </div>

  
  </body>
</html>
